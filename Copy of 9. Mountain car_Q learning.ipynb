{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPE+03J0VZOV1V4wo/1nVw4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"H5faBejfFosb"},"outputs":[],"source":["import gym\n","import numpy as np\n","\n","class QLearningAgent:\n","    def __init__(self, state_size, action_size, alpha=0.01, gamma=0.99, epsilon=1.0):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        self.alpha = alpha    # learning rate\n","        self.gamma = gamma    # discount factor\n","        self.epsilon = epsilon  # exploration rate\n","        self.weights = np.zeros((self.state_size, self.action_size))\n","        \n","    def get_action(self, state):\n","        if np.random.rand() <= self.epsilon:\n","            # explore\n","            return np.random.choice(self.action_size)\n","        # exploit\n","        q_values = np.dot(state, self.weights)\n","        return np.argmax(q_values)\n","        \n","    def learn(self, state, action, reward, next_state, done):\n","        q_values = np.dot(state, self.weights)\n","        next_q_values = np.dot(next_state, self.weights)\n","        target = reward + (1 - done) * self.gamma * np.max(next_q_values)\n","        td_error = target - q_values[action]\n","        self.weights += self.alpha * td_error * np.reshape(state, (self.state_size, 1)) * np.reshape(np.eye(self.action_size)[action], (1, self.action_size))\n","        # reduce exploration rate\n","        self.epsilon = max(0.1, self.epsilon * 0.999)\n","\n","# Create a MountainCar environment\n","env = gym.make('MountainCar-v0')\n","\n","# Create a Q-learning agent\n","agent = QLearningAgent(state_size=env.observation_space.shape[0], action_size=env.action_space.n)\n","\n","# Train the agent\n","num_episodes = 1000\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    done = False\n","    total_reward = 0\n","    while not done:\n","        action = agent.get_action(state)\n","        next_state, reward, done, _ = env.step(action)\n","        agent.learn(state, action, reward, next_state, done)\n","        state = next_state\n","        total_reward += reward\n","    print(\"Episode {}/{}: Total reward = {}\".format(episode+1, num_episodes, total_reward))\n","\n","# Test the agent\n","num_episodes = 10\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    done = False\n","    total_reward = 0\n","    while not done:\n","        action = agent.get_action(state)\n","        next_state, reward, done, _ = env.step(action)\n","        state = next_state\n","        total_reward += reward\n","    print(\"Episode {}/{}: Total reward = {}\".format(episode+1, num_episodes, total_reward))\n","\n","# Close the environment\n","env.close()"]}]}